# Days-09~10

## Python语言进阶

### 重要知识点

#### 生成式(推导式)的用法(可用来生成列表、集合和字典)
```
prices = {
    'AAPL': 191.88,
    'GOOG': 1186.96,
    'IBM': 149.24,
    'ORCL': 48.44,
    'ACN': 166.89,
    'FB': 208.09,
    'SYMC': 21.29
}
# 用股票价格大于100元的股票构造一个新的字典
prices2 = {key: value for key, value in prices.items() if value > 100}
print(prices2)
```
```
#其中该推导式是常用的字典生成方式
prices = {key: value for key, value in prices.item() if value > 100}
print(prices)

#或是用推导式来生成列表，则有如下
data = [x**2 for x in range(0, 5)]
print(data)

#或是用推导式来生成集合，则有如下
data = {x**2 for x in range(0, 5)}
print(data)
```

#### headq模块(堆排序)
```
#从列表中找出最大或最小的N个元素
#堆结构(大根堆/小根堆)

import heapq

list1 = [34, 25, 12, 99, 87, 63, 58, 78, 88, 92]
list2 = [
    {'name': 'IBM', 'shares': 100, 'price': 91.1},
    {'name': 'AAPL', 'shares': 50, 'price': 543.22},
    {'name': 'FB', 'shares': 200, 'price': 21.09},
    {'name': 'HPQ', 'shares': 35, 'price': 31.75},
    {'name': 'YHOO', 'shares': 45, 'price': 16.35},
    {'name': 'ACME', 'shares': 75, 'price': 115.65}
]

print(heapq.nlargest(3, list1)) #选出前三个最大的元素
print(heapq.nsmallest(3, list1)) #选出前三个最小的元素

#选出前两个最大的price元素并输出其属性
print(heapq.nlargest(2, list2, key = lambda x: x['price']))

#选出前两个最大的shares元素并输出其属性
print(heapq.nlargest(2, list2, key = lambda x: x['shares']))
```

#### itertools模块
```
#迭代工具模块

import itertools

itertools.permutations('ABCD') #产生ABCD的全排列

itertools.combinations('ABCDE', 3) #产生ABCDE的五选三组合

itertools.product('ABCD', '123') #产生ABCD和123的笛卡尔积

itertools.cycle(('A', 'B', 'C')) #产生ABC的无限循环序列

itertools.repeat(None, 5) #产生零次的序列
```

#### collections模块

namedtuple: 命令元组，它是一个类工厂，接受类型的名称和属性列表来创建一个类

deque: 双端队列，是列表的替代实现，在头尾添加和删除元素时，deque会表现出更好的性能，渐进时间复杂度是$O(1)$

Counter: dict的子类，键是元素，值是元素的计数，它的most_common()方法可以帮助我们获取出现频率最高的元素，跟dict的关系应该设计为关联关系更为合理

OrderedDict: dict的子类，用以记录键值对插入的顺序

defaultdict: 类似于字典类型，但是可以通过默认的工厂函数来获得键对应的默认值，相比于字典中的setdefault()方法，这种做法更加高效

```
#找出序列中出现次数最多的元素
from collections import Counter

words = [
    'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes',
    'the', 'eyes', 'the', 'eyes', 'the', 'eyes', 'not', 'around',
    'the', 'eyes', "don't", 'look', 'around', 'the', 'eyes',
    'look', 'into', 'my', 'eyes', "you're", 'under'
]
counter = Counter(words)
print(counter.most_common(3))
```
```
#将list内不存在的key值自动返回预先设置的默认值
from collections import defaultdict

data = [(1, 3), (2, 1), (1, 4), (2, 5), (3, 7)]
d = defaultdict(list)

for k, v in data:
    d[k].append(v)
```
```
# 比如当我们拥有海量的数据，我们不知道它的数量，但是想要保留最后出现的指定数量的数据的时候，就可以使用deque
from collections import deque

dque = deque(maxlen=10)

for i in f.read():
    dque.append(i)
```
```
# 定义一个类时，可以用namedtuple，通过传入defaults参数来定义缺失值

Student = namedtuple('Student', ['name', 'score', 'age'], defaults=(0, 0))
```

#### 数据结构和算法

+ 渐进时间复杂度的大O标记：

 - O(c)：常量时间复杂度-布隆过滤器/哈希存储

 - O(log2n)：对数时间复杂度-折半查找(二分查找)

 - O(n)：线性时间复杂度-顺序查找/计数排序

 - O(n*log2n)：对数线性时间复杂度-高级排序算法(归并排序、快速排序)

 - O(n*n)：平方时间复杂度-简单排序算法(选择排序、插入排序、冒泡排序)

 - O(n*n*n)：立方时间复杂度-Floyd算法/矩阵乘法运算

 - O(2^n)：几何级时间复杂度-汉诺塔

 - O(n!)：阶乘时间复杂度-旅行经销商问题-NPC

##### 简单选择排序
```
def select_sort(items, comp=lambda x,y: x < y): #比较大小
    items = items[:]
    for i in range(len(items) - 1):
        min_index = i
        for j in range(i+1, len(items)):
            if comp(items[j], items[min_index]):
                min_index = j
        items[i], items[min_index] = items[min_index], items[i]
    return items
```
##### 冒泡排序
```
def bubble_sort(items, comp=lambda x, y :x > y):
    items = items[:]
    for i in range(len(items) - 1):
        swapped = False
        for j in range(len(items) - 1 - i):
            if comp(items[j], items[j+1]):
                items[j], items[j+1] = items[j+1], items[j]
                swapped = True
        if not swapped:
            break
    return items
```
##### 搅拌排序(冒泡排序升级版)
```
def bubble_sort(items, comp=lambda x, y :x > y):
    items = items[:]
    for i in range(len(items) - 1):
        swapped = False
        for j in range(len(items) - 1 - i):
            if comp(items[j], items[j+1]):
                items[j], items[j+1] = items[j+1], items[j]
                swapped = True
        if swapped:
            swapped = False
            for j in range(len(items) - 2 - i, i, -1):
                if comp(items[j - 1], items[j]):
                    items[j], items[j - 1] = items[j - 1], items[j]
                    swapped = True
        if not swapped:
            break
    return items
```
##### 合并排序(将两个有序的列表合并成一个有序的列表)
```
def merge(items1, items2, comp=lambda x, y: x < y):
    items = []
    index1, index2 = 0, 0
    while index1 < len(items1) and index2 < len(items2):
        if comp(items1[index1], items2[index2]):
            items.append(items[index1])
            index1 += 1
        else:
            items.append(items2[index2])
            index2 += 1
    items += items1[index1:]
    items += items2[index2:]
    return items
```
##### 归并排序
```
def merge_sort(items, comp=lambda x, y: x < y):
    return _merge_sort(list(items), comp)

#其中merge()引用上述的合并排序
def _merge_sort(items, comp):
    if len(items) < 2:
        return items
    mid = len(items) // 2
    left = _merge_sort(items[:mid], comp)
    right = _merge_sort(items[mid:], comp)
    return merge(left, right, comp)
```
##### 顺序查找
```
def seq_search(items, key):
    for index, item in enumerate(items):
        if item == key:
            return index
    return -1
```
##### 折半查找
```
def bin_search(items, key):
    start, end = 0, len(items) - 1
    while start <= end:
        mid = (start + end) // 2
        if key > items[mid]:
            start = mid + 1
        elif key < items[mid]:
            end = mid - 1
        else:
            return mid
    return -1    
```
##### 常用算法

1.穷举法(暴力破解法)

2.贪婪法

3.最好的选择，不追求最优解，快速找到满意解

4.分治法

5.回溯法

6.动态规划

上述算法可以通过leetcode刷题总结，稍后我会另开链接用以记录刷题心得

#### 函数的使用方式

##### 函数的用法

◆ 函数可以赋值给变量
◆ 函数可以作为函数的参数
◆ 函数可以作为函数的返回值

##### 高阶函数的用法(filter、map以及它们的替代品)
```
items1 = list(map(lambda x: x ** 2, filter(lambda x: x % 2, range(1, 10))))
items2 = [x ** 2 for x in range(1, 10) if x % 2]
```

##### 位置参数、可变参数、关键字参数、命名关键字参数

##### 参数的元信息(代码可读性问题)

##### 匿名函数和内联函数的用法(lambda 函数)

##### 闭包和作用域问题

◆ Python搜索变量的LEGB顺序(Local >>> Embedded >>> Global >>> Built-in)
◆ ```global``` 和```nonlocal```关键字的作用
```global```:声明或定义全局变量(要么直接使用现有的全局作用域的变量，要么定义一个变量放到全局作用域)
```nonlocal```:声明使用嵌套作用域的变量(嵌套作用域必须存在该变量，否则报错)

##### 装饰器函数(使用装饰器和取消装饰器)

#### 面向对象相关知识

##### 三大支柱：封装、继承、多态

##### 对象的复制(深复制/深拷贝/深度克隆和浅复制/浅拷贝/影子克隆)(这一块掌握的不太好，后续需要学习)

##### 垃圾回收、循环引用和弱引用(这一块掌握的不太好，后续需要学习)

Python使用了自动化内存管理，这种管理机制以引用计数为基础，同时也引入了标记-清除和分代收集两种机制为辅的策略。
```
typedef struct _object {
    /* 引用计数 */
    int ob_refcnt;
    /* 对象指针 */
    struct _typeobject *ob_type;
} PyObject;
```
```
/* 增加引用计数的宏定义 */
#define Py_INCREF(op)   ((op)->ob_refcnt++)
/* 减少引用计数的宏定义 */
#define Py_DECREF(op) \ //减少计数
    if (--(op)->ob_refcnt != 0) \
        ; \
    else \
        __Py_Dealloc((PyObject *)(op))
```
导致引用计数+1的情况：
 + 对象被创建，例如```a = 23```
 + 对象被引用，例如```b = a```
 + 对象被作为参数，传入到一个函数中，例如```f(a)```
 + 对象作为一个元素，存储在容器中，例如```list1 = [a, a]```

导致引用计数-1的情况：
 + 对象的别名被显示销毁，例如```del a```
 + 对象的别名被赋予新的对象，例如```a = 24```
 + 一个对象离开它的作用域，例如f函数执行完毕时，f函数中的局部变量(全局变量不会)
 + 对象所在的容器被销毁，或从容器中删除对象

引用计数可能会导致循环引用问题，而循环引用会导致内存泄露，如下代码所示。
```
# 循环引用会导致内存泄露 - Python除了引用技术还引入了标记清理和分代回收
# 在Python 3.6以前如果重写__del__魔术方法会导致循环引用处理失效
# 如果不想造成循环引用可以使用弱引用
list1 = []
list2 = [] 
list1.append(list2)
list2.append(list1)
```
为了解决这个问题，Python中引入了"标记-清除"和"分代收集"。在创建一个对象的时候，对象被放在第一代中，如果在第一代的垃圾检查中对象存活了下来，该对象就会被放到第二代中，同理在第二代的垃圾检查中对象存活下来，该对象就会被放到第三代中

以下情况会导致垃圾回收：
 + 调用```gc.collect```
 + ```gc```模块的计数器达到阀值
 + 程序退出

如果循环引用中两个对象都定义了```__del__方法```，```gc```模块不会销毁这些不可达对象，因为gc模块不知道应该先调用哪个对象的```__del__```方法，这而已通过weakref模块构造弱引用的方式来解决循环引用的问题

+ 面向对象设计原则
  - 单一职责原则(SRP) - 一个类只做该做的事情(类的设计要高内聚)
  - 开闭原则(OCP) - 软件实体应该对扩展开发对修改关闭
  - 依赖倒转原则(DIP) - 面向抽象编程(在弱类型语言中已经被弱化)
  - 里氏替换原则(LSP) - 任何时候可以用子类对象替换掉父类对象
  - 接口隔离原则(ISP) - 接口要小而专不要大而全(Python没有接口的概念)
  - 合成聚合复用原则(CARP) - 优先使用强关联关系而不是继承关系复用代码
  - 最少知识原则(迪米特法则， LoD) - 不要给没有必然联系的对象发消息

#### 迭代器和生成器

 + 迭代器是实现了迭代器协议的对象
  - Python中没有像```protocol```或```interface```这样的定义协议的关键字
  - Python中用魔术方法表示协议
  - ```__iter__```和```__next__```魔术方法就是迭代器协议
   ```
   class Fib(object):
    """迭代器"""

    def __init__(self, num):
        self.num = num
        self.a, self.b = 0, 1
        self.idx = 0

    def __iter__(self):
        return self

    def __next__(self):
        if self.idx < self.num:
            self.a, self.b = self.b, self.a + self.b
            self.idx += 1
            return self.a
        raise StopIteration()
   ```
 + 生成器是语法简化版的迭代器
   ```
   def fib(num):
       """生成器"""
       a, b = 0, 1
       for _ in range(num):
           a, b = b, a + b
           yield a
   ```
 + 生成器进化为协程
   生成器对象可以使用```send()```方法发送数据，发送的数据会成为生成器函数中通过```yield```表达式获得的值。这样，生成器就可以作为协程使用，协程简单的说就是可以相互协作的子程序
   ```
   def calc_avg():
    """流式计算平均值"""
    total, counter = 0, 0
    avg_value = None
    while True:
        value = yield avg_value
        total, counter = total + value, counter + 1
        avg_value = total / counter

    gen = calc_avg()
    next(gen)
    print(gen.send(10))
    print(gen.send(20))
    print(gen.send(30))
   ```

#### 并发编程

Python中实现并发编程的三种方案：多线程、多进程和异步I/O。并发编程的好处在于可以提升程序的执行效率以及改善用户体验；坏处在于并发的程序不容易开发和调试，同时对其他程序来说它并不友好

+ 多线程：Python中提供了```Thread```类并辅以```Lock```，```Condition```,```Event```,```Semaphore```和```Barrier```。Python中有GIL来防止多个线程同时执行本地字节码，这个锁对于CPython是必须的，因为CPython的内存管理并不是线程安全的，因为GIL的存在多线程并不能发挥CPU的多核特性
```
"""
面试题：进程和线程的区别和联系？
进程 - 操作系统分配内存的基本单位 - 一个进程可以包含一个或多个线程
线程 - 操作系统分配CPU的基本单位
并发编程（concurrent programming）
1. 提升执行性能 - 让程序中没有因果关系的部分可以并发的执行
2. 改善用户体验 - 让耗时间的操作不会造成程序的假死
"""
import glob
import os
import threading

from PIL import Image

PREFIX = 'thumbnails'


def generate_thumbnail(infile, size, format='PNG'):
    """生成指定图片文件的缩略图"""
    file, ext = os.path.splitext(infile)
    file = file[file.rfind('/') + 1:]
    outfile = f'{PREFIX}/{file}_{size[0]}_{size[1]}.{ext}'
    img = Image.open(infile)
    img.thumbnail(size, Image.ANTIALIAS)
    img.save(outfile, format)


def main():
    """主函数"""
    if not os.path.exists(PREFIX):
        os.mkdir(PREFIX)
    for infile in glob.glob('images/*.png'):
        for size in (32, 64, 128):
            # 创建并启动线程
            threading.Thread(
                target=generate_thumbnail,
                args=(infile, (size, size))
            ).start()


if __name__ == '__main__':
    main()
```

+ 多个线程竞争资源的情况
```
"""
多线程程序如果没有竞争资源处理起来通常也比较简单
当多个线程竞争临界资源的时候如果缺乏必要的保护措施就会导致数据错乱
说明：临界资源就是被多个线程竞争的资源
"""
import time
import threading

from concurrent.futures import ThreadPoolExecutor


class Account(object):
    """银行账户"""

    def __init__(self):
        self.balance = 0.0
        self.lock = threading.Lock()

    def deposit(self, money):
        # 通过锁保护临界资源
        with self.lock:
            new_balance = self.balance + money
            time.sleep(0.001)
            self.balance = new_balance


def main():
    """主函数"""
    account = Account()
    # 创建线程池
    pool = ThreadPoolExecutor(max_workers=10)
    futures = []
    for _ in range(100):
        future = pool.submit(account.deposit, 1)
        futures.append(future)
    # 关闭线程池
    pool.shutdown()
    for future in futures:
        future.result()
    print(account.balance)


if __name__ == '__main__':
    main()
```

修改上面的程序，启动5个线程向账户中存钱，5个线程从账户中取钱，取钱时如果余额不足就暂停线程进行等待。为了达到上述目标，需要对存钱和取钱的线程进行调度，在余额不足时取钱的线程暂停并释放锁，而存钱的线程将钱存入后要通知取钱的线程，使其从暂停状态被唤醒。可以使用```threading```模块的```Condition```来实现线程调度，该对象也是基于锁来创建的，代码如下所示：
```
"""
多个线程竞争一个资源 - 保护临界资源 - 锁（Lock/RLock）
多个线程竞争多个资源（线程数>资源数） - 信号量（Semaphore）
多个线程的调度 - 暂停线程执行/唤醒等待中的线程 - Condition
"""
from concurrent.futures import ThreadPoolExecutor
from random import randint
from time import sleep

import threading


class Account:
    """银行账户"""

    def __init__(self, balance=0):
        self.balance = balance
        lock = threading.RLock()
        self.condition = threading.Condition(lock)

    def withdraw(self, money):
        """取钱"""
        with self.condition:
            while money > self.balance:
                self.condition.wait()
            new_balance = self.balance - money
            sleep(0.001)
            self.balance = new_balance

    def deposit(self, money):
        """存钱"""
        with self.condition:
            new_balance = self.balance + money
            sleep(0.001)
            self.balance = new_balance
            self.condition.notify_all()


def add_money(account):
    while True:
        money = randint(5, 10)
        account.deposit(money)
        print(threading.current_thread().name, 
              ':', money, '====>', account.balance)
        sleep(0.5)


def sub_money(account):
    while True:
        money = randint(10, 30)
        account.withdraw(money)
        print(threading.current_thread().name, 
              ':', money, '<====', account.balance)
        sleep(1)


def main():
    account = Account()
    with ThreadPoolExecutor(max_workers=15) as pool:
        for _ in range(5):
            pool.submit(add_money, account)
        for _ in range(10):
            pool.submit(sub_money, account)


if __name__ == '__main__':
    main()
```

+ 多进程：多进程可以有效解决GIL的问题，实现多进程主要的类是```Process```，其他辅助的类跟```threading```模块中的类似，进程间共享数据可以使用管道、套接字等，在```multiprocessing```模块中有一个```Queue```类，它基于管道和锁机制提供了多个进程共享的队列。下面是官方文档上关于多进程和进程池的一个示例。
```
"""
多进程和进程池的使用
多线程因为GIL的存在不能够发挥CPU的多核特性
对于计算密集型任务应该考虑使用多进程
"""
import concurrent.futures
import math

PRIMES = [
    1116281,
    1297337,
    104395303,
    472882027,
    533000389,
    817504243,
    982451653,
    112272535095293,
    112582705942171,
    112272535095293,
    115280095190773,
    115797848077099,
    1099726899285419
] * 5


def is_prime(n):
    """判断素数"""
    if n % 2 == 0:
        return False

    sqrt_n = int(math.floor(math.sqrt(n)))
    for i in range(3, sqrt_n + 1, 2):
        if n % i == 0:
            return False
    return True


def main():
    """主函数"""
    with concurrent.futures.ProcessPoolExecutor() as executor:
        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):
            print('%d is prime: %s' % (number, prime))


if __name__ == '__main__':
    main()
```

重点：多线程和多进程的比较

以下情况需要使用多线程：

 i. 程序需要维护许多共享的状态(尤其是可变状态)，Python中的列表、字典、集合都是线程安全的，所以使用线程而不是进程维护共享状态的代价相对较小

 ii. 程序会花费大量时间在I/O操作上，没有太多并行计算的需求且不需占用太多的内存

以下情况需要使用多进程：
 i. 程序执行计算密集型任务(如:字节码操作、数据处理、科学计算)

 ii. 程序的输入可以并行的分成块，并且可以将运算结果合并

 iii. 程序在内存使用方面没有任何限制且不强依赖于I/O操作(如:读写文件、套接字等)

+ 异步处理

  从调度程序的任务队列中挑选任务，该调度程序以交叉的形式执行这些任务，我们并不能保证任务将以某种顺序去执行，因为执行顺序取决于队列中的一项任务是否愿意将CPU处理时间让位给另一项任务。异步任务通常通过多任务协作处理的方式来实现，由于执行时间和顺序的不确定，因此需要通过回调式编程或者```future```对象来获取任务执行的结果。Python3通过```asyncio```模块和```await```和```async```关键字来支持异步处理
```
"""
异步I/O - async / await
"""
import asyncio


def num_generator(m, n):
    """指定范围的数字生成器"""
    yield from range(m, n + 1)


async def prime_filter(m, n):
    """素数过滤器"""
    primes = []
    for i in num_generator(m, n):
        flag = True
        for j in range(2, int(i ** 0.5 + 1)):
            if i % j == 0:
                flag = False
                break
        if flag:
            print('Prime =>', i)
            primes.append(i)

        await asyncio.sleep(0.001)
    return tuple(primes)


async def square_mapper(m, n):
    """平方映射器"""
    squares = []
    for i in num_generator(m, n):
        print('Square =>', i * i)
        squares.append(i * i)

        await asyncio.sleep(0.001)
    return squares


def main():
    """主函数"""
    loop = asyncio.get_event_loop()
    future = asyncio.gather(prime_filter(2, 100), square_mapper(1, 100))
    future.add_done_callback(lambda x: print(x.result()))
    loop.run_until_complete(future)
    loop.close()


if __name__ == '__main__':
    main()
```

说明：

上面的代码使用```get_event_loop```函数获得系统默认的事件循环，通过```gather```函数可以获得一个```future```对象，```future```对象的```add_done_callback```可以添加执行完成时的回调函数，```loop```对象的```run_until_complete```方法可以等待通过```future```对象获得协程执行结果

Python中有一个名为```aiohttp```的三方库，它提供了异步的HTTP客户端和服务器，这个三方库可以跟```asyncio```模块一起工作，并提供了对```Future```对象的支持。Python 3.6中引入了```async```和```await```来定义异步执行的函数以及创建异步上下文，在Python 3.7中它们正式成为了关键字。下面的代码异步的从5个URL中获取页面并通过正则表达式的命名捕获组提取了网站的标题。
```
import asyncio
import re

import aiohttp

PATTERN = re.compile(r'\<title\>(?P<title>.*)\<\/title\>')


async def fetch_page(session, url):
    async with session.get(url, ssl=False) as resp:
        return await resp.text()


async def show_title(url):
    async with aiohttp.ClientSession() as session:
        html = await fetch_page(session, url)
        print(PATTERN.search(html).group('title'))


def main():
    urls = ('https://www.python.org/',
            'https://git-scm.com/',
            'https://www.jd.com/',
            'https://www.taobao.com/',
            'https://www.douban.com/')
    loop = asyncio.get_event_loop()
    cos = [show_title(url) for url in urls]
    loop.run_until_complete(asyncio.wait(cos))
    loop.close()


if __name__ == '__main__':
    main()
```

重点：异步I/O与多进程的比较

当程序不需要真正的并发性或并行性，而是更多的依赖于异步处理和回调时，```asyncio```就是一种很好的选择，如果程序中有大量的等待与休眠时，也应该考虑```asyncio```，它很适合编写没有实时数据处理需求的Web应用服务器

要实现任务的异步化，可以使用名为```Celery```的三方库，```Celery```是Python编写的分布式任务队列，它使用分布式消息进行工作，可以基于RabbitMQ或Redis来作为后端的消息代理(后续会学到Redis)